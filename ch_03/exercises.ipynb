{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data/parsed.csv file and the material from this chapter, complete the following exercises to practice your pandas skills:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "#### Load stock data\n",
    "We want to look at data for the Facebook, Apple, Amazon, Netflix, and Google (FAANG) stocks, but we were given each as a separate CSV file (obtained using the stock_analysis package we will build in Chapter 7, Financial Analysis â€“ Bitcoin and the Stock Market). Combine them into a single file and store the dataframe of the FAANG data as faang for the rest of the exercises:\n",
    "\n",
    "a) Read in the aapl.csv, amzn.csv, fb.csv, goog.csv, and nflx.csv files.\n",
    "\n",
    "b) Add a column to each dataframe, called ticker, indicating the ticker symbol it is for (Apple's is AAPL, for example); this is how you look up a stock. In this case, the filenames happen to be the ticker symbols.\n",
    "\n",
    "c) Append them together into a single dataframe.\n",
    "\n",
    "d) Save the result in a CSV file called faang.csv.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = pd.read_csv('./exercises/aapl.csv').assign(ticker='AAPL')\n",
    "faang = faang.append(pd.read_csv('./exercises/amzn.csv').assign(ticker='AMZN'))\n",
    "faang = faang.append(pd.read_csv('./exercises/fb.csv').assign(ticker='FB'))\n",
    "faang = faang.append(pd.read_csv('./exercises/goog.csv').assign(ticker='GOOG'))\n",
    "faang = faang.append(pd.read_csv('./exercises/nflx.csv').assign(ticker='NFLX'))\n",
    "faang.to_csv('./exercises/faang.csv', index=False)\n",
    "\n",
    "## Book Solution\n",
    "# faang = pd.DataFrame()\n",
    "# for ticker in ['fb', 'aapl', 'amzn', 'nflx', 'goog']:\n",
    "#     df = pd.read_csv(f'../../ch_03/exercises/{ticker}.csv')\n",
    "#     # make the ticker the first column\n",
    "#     df.insert(0, 'ticker', ticker.upper())\n",
    "#     faang = faang.append(df)\n",
    "\n",
    "# faang.to_csv('faang.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "#### Initial cleaning\n",
    "With faang, use type conversion to cast the values of the date column into datetimes and the volume column into integers. Then, sort by date and ticker.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1255 entries, 0 to 1254\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    1255 non-null   datetime64[ns]\n",
      " 1   high    1255 non-null   float64       \n",
      " 2   low     1255 non-null   float64       \n",
      " 3   open    1255 non-null   float64       \n",
      " 4   close   1255 non-null   float64       \n",
      " 5   volume  1255 non-null   int32         \n",
      " 6   ticker  1255 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(4), int32(1), object(1)\n",
      "memory usage: 73.5+ KB\n"
     ]
    }
   ],
   "source": [
    "faang = pd.read_csv('./exercises/faang.csv')\n",
    "faang.date = pd.to_datetime(faang.date)\n",
    "faang.volume = pd.to_numeric(faang.volume, downcast='integer')\n",
    "faang.sort_values(by=['date', 'ticker'], inplace=True)\n",
    "faang.info()\n",
    "\n",
    "## Book Solution\n",
    "# faang = faang.assign(\n",
    "#     date=lambda x: pd.to_datetime(x.date),\n",
    "#     volume=lambda x: x.volume.astype(int)\n",
    "# ).sort_values(\n",
    "#     ['date', 'ticker']\n",
    "# )\n",
    "\n",
    "# faang.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "#### Find the seven rows in faang with the lowest value for volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>1135.819946</td>\n",
       "      <td>1100.020020</td>\n",
       "      <td>1135.819946</td>\n",
       "      <td>1102.890015</td>\n",
       "      <td>679000.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>1037.589966</td>\n",
       "      <td>1022.398987</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1023.880005</td>\n",
       "      <td>691500.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>1080.469971</td>\n",
       "      <td>1066.150024</td>\n",
       "      <td>1079.000000</td>\n",
       "      <td>1079.239990</td>\n",
       "      <td>766800.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>1159.589966</td>\n",
       "      <td>1149.589966</td>\n",
       "      <td>1156.979980</td>\n",
       "      <td>1152.839966</td>\n",
       "      <td>798400.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>1255.541992</td>\n",
       "      <td>1246.010010</td>\n",
       "      <td>1249.900024</td>\n",
       "      <td>1249.099976</td>\n",
       "      <td>848600.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>1194.625977</td>\n",
       "      <td>1205.020020</td>\n",
       "      <td>1207.770020</td>\n",
       "      <td>870800.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2018-08-22</td>\n",
       "      <td>1211.839966</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1207.329956</td>\n",
       "      <td>887400.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date         high          low         open        close    volume  \\\n",
       "126  2018-07-03  1135.819946  1100.020020  1135.819946  1102.890015  679000.0   \n",
       "226  2018-11-23  1037.589966  1022.398987  1030.000000  1023.880005  691500.0   \n",
       "99   2018-05-24  1080.469971  1066.150024  1079.000000  1079.239990  766800.0   \n",
       "130  2018-07-10  1159.589966  1149.589966  1156.979980  1152.839966  798400.0   \n",
       "152  2018-08-09  1255.541992  1246.010010  1249.900024  1249.099976  848600.0   \n",
       "159  2018-08-20  1211.000000  1194.625977  1205.020020  1207.770020  870800.0   \n",
       "161  2018-08-22  1211.839966  1199.000000  1200.000000  1207.329956  887400.0   \n",
       "\n",
       "    ticker  \n",
       "126   GOOG  \n",
       "226   GOOG  \n",
       "99    GOOG  \n",
       "130   GOOG  \n",
       "152   GOOG  \n",
       "159   GOOG  \n",
       "161   GOOG  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang.nsmallest(7, 'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "#### Convert to long format\n",
    "Right now, the data is somewhere between long and wide format. Use melt() to make it completely long format. Hint: date and ticker are our ID variables (they uniquely identify each row). We need to melt the rest so that we don't have separate columns for open, high, low, close, and volume.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.head(5)\n",
    "faang_long = faang.melt(id_vars=['date', 'ticker'], value_vars=['open', 'high', 'low', 'close', 'volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "#### Handling a glitch\n",
    "Suppose we found out that on July 26, 2018 there was a glitch in how the data was recorded. How should we handle this? Note that there is no coding required for this exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Book Solution\n",
    "> Given that this is a large data set (~ 1 year), we would be tempted to just drop that date and interpolate. However, some preliminary research on that date for the FAANG stocks reveals that FB took a huge tumble that day. If we had interpolated, we would have missed the magnitude of the drop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "#### Load ECDC data.\n",
    "The European Centre for Disease Prevention and Control (ECDC) provides an open dataset on COVID-19 cases called daily number of new reported cases of COVID-19 by country worldwide (https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide). This dataset is updated daily, but we will use a snapshot that contains data from January 1, 2020 through September 18, 2020. Clean and pivot the data so that it is in wide format:\n",
    "\n",
    "a) Read in the covid19_cases.csv file.\n",
    "\n",
    "b) Create a date column using the data in the dateRep column and the pd.to_datetime() function.\n",
    "\n",
    "c) Set the date column as the index and sort the index.\n",
    "\n",
    "d) Replace all occurrences of United_States_of_America and United_Kingdom with USA and UK, respectively. Hint: the replace() method can be run on the dataframe as a whole.\n",
    "\n",
    "e) Using the countriesAndTerritories column, filter the cleaned COVID-19 cases data down to Argentina, Brazil, China, Colombia, India, Italy, Mexico, Peru, Russia, Spain, Turkey, the UK, and the USA.\n",
    "\n",
    "f) Pivot the data so that the index contains the dates, the columns contain the country names, and the values are the case counts (the cases column). Be sure to fill in NaN values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covid_df = pd.read_csv('./exercises/covid19_cases.csv')\n",
    "# covid_df['date'] = pd.to_datetime(covid_df.dateRep)\n",
    "# covid_df = covid_df.drop(columns=['dateRep', 'day', 'month', 'year'])\n",
    "# covid_df.set_index('date', inplace=True)\n",
    "# covid_df.sort_index\n",
    "\n",
    "selection_list = ('Argentina', 'Brazil', 'China', 'Columbia', 'India', 'Italy', 'Mexico', 'Peru', 'Russia', 'Spain', 'Turkey', 'UK', 'USA')\n",
    "\n",
    "covid_df = pd.read_csv('./exercises/covid19_cases.csv').assign(\n",
    "    date=lambda x: pd.to_datetime(x.dateRep, format='%d/%m/%Y')\n",
    ").set_index('date')\n",
    "covid_df.countriesAndTerritories.replace('United_States_of_America','USA', inplace=True)\n",
    "covid_df.countriesAndTerritories.replace('United_Kingdom','UK', inplace=True)\n",
    "covid_df = covid_df[covid_df.countriesAndTerritories.isin(selection_list)]\n",
    "\n",
    "covid_df_pivot = covid_df.reset_index().pivot(index='date', columns='countriesAndTerritories', values='cases').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7\n",
    "#### Find the 20 counteries with the largest COVI19 case totals.\n",
    "In order to determine the case totals per country efficiently, we need the aggregation skills we will learn about in Chapter 4, Aggregating Pandas DataFrames, so the ECDC data in the covid19_cases.csv file has been aggregated for us and saved in the covid19_total_cases.csv file. It contains the total number of cases per country. Use this data to find the 20 countries with the largest COVID-19 case totals. Hints: when reading in the CSV file, pass in index_col='cases', and note that it will be helpful to transpose the data before isolating the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>index</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>6724667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>5308014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>4495183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>1091186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peru</th>\n",
       "      <td>756412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colombia</th>\n",
       "      <td>750471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>688954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South_Africa</th>\n",
       "      <td>657627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>640040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>601700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>442827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>428696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iran</th>\n",
       "      <td>416198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>385936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bangladesh</th>\n",
       "      <td>345805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saudi_Arabia</th>\n",
       "      <td>328720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iraq</th>\n",
       "      <td>311690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pakistan</th>\n",
       "      <td>305031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>299810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>294932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "index           cases\n",
       "USA           6724667\n",
       "India         5308014\n",
       "Brazil        4495183\n",
       "Russia        1091186\n",
       "Peru           756412\n",
       "Colombia       750471\n",
       "Mexico         688954\n",
       "South_Africa   657627\n",
       "Spain          640040\n",
       "Argentina      601700\n",
       "Chile          442827\n",
       "France         428696\n",
       "Iran           416198\n",
       "UK             385936\n",
       "Bangladesh     345805\n",
       "Saudi_Arabia   328720\n",
       "Iraq           311690\n",
       "Pakistan       305031\n",
       "Turkey         299810\n",
       "Italy          294932"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Book Solution\n",
    "pd.read_csv('./exercises/covid19_total_cases.csv', index_col='index').T.nlargest(20, 'cases').sort_values('cases', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e23f2375a57999574a0269b283c75eed81f3eafcf4544127d3a066ff8356cdc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
